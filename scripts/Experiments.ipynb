{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47301e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4fe0afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wili_2018 (/Users/kristina/.cache/huggingface/datasets/wili_2018/WiLI-2018 dataset/1.1.0/78d7fe4a9d0a01168e45657f302c776ee0afc0978d44e2c3759f4c4975b845f5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1229f91bd82a4072bc0f0cbb7e460c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "root = str(Path.cwd().parent)\n",
    "sys.path.append(root)\n",
    "\n",
    "from initializer import annotation_df, languages_set\n",
    "from ngram_model import NGramsClassifier\n",
    "from bert_model import TransformerLanguageDetection\n",
    "from dataset import WILI2018Dataset\n",
    "from metrics import Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d245625",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# WILI-2018 dataset extracting labels' annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad2ab6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>English</th>\n",
       "      <th>Wiki Code</th>\n",
       "      <th>ISO 369-3</th>\n",
       "      <th>German</th>\n",
       "      <th>Language family</th>\n",
       "      <th>Writing system</th>\n",
       "      <th>Remarks</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ace</td>\n",
       "      <td>Achinese</td>\n",
       "      <td>ace</td>\n",
       "      <td>ace</td>\n",
       "      <td>Achinesisch</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afr</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>af</td>\n",
       "      <td>afr</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>als</td>\n",
       "      <td>Alemannic German</td>\n",
       "      <td>als</td>\n",
       "      <td>gsw</td>\n",
       "      <td>Alemannisch</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(ursprünglich nur Elsässisch)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amh</td>\n",
       "      <td>Amharic</td>\n",
       "      <td>am</td>\n",
       "      <td>amh</td>\n",
       "      <td>Amharisch</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ang</td>\n",
       "      <td>Old English</td>\n",
       "      <td>ang</td>\n",
       "      <td>ang</td>\n",
       "      <td>Altenglisch</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(ca. 450-1100)</td>\n",
       "      <td>Angelsächsisch</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label           English Wiki Code ISO 369-3       German Language family  \\\n",
       "0   ace          Achinese       ace       ace  Achinesisch    Austronesian   \n",
       "1   afr         Afrikaans        af       afr    Afrikaans   Indo-European   \n",
       "2   als  Alemannic German       als       gsw  Alemannisch   Indo-European   \n",
       "3   amh           Amharic        am       amh    Amharisch    Afro-Asiatic   \n",
       "4   ang      Old English        ang       ang  Altenglisch   Indo-European   \n",
       "\n",
       "  Writing system                        Remarks        Synonyms   id  \n",
       "0            NaN                            NaN             NaN   21  \n",
       "1            NaN                            NaN             NaN   90  \n",
       "2            NaN  (ursprünglich nur Elsässisch)             NaN  221  \n",
       "3            NaN                            NaN             NaN  123  \n",
       "4            NaN                 (ca. 450-1100)  Angelsächsisch  129  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3e5c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = WILI2018Dataset(\"train\")\n",
    "test_set = WILI2018Dataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9643dce3",
   "metadata": {},
   "source": [
    "#### Dataset contains equal amount of samples for each language (500 sentences each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81647e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sizes = [10]*10\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, labels=languages_set, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc86657",
   "metadata": {},
   "source": [
    "The datatest is balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208976b4",
   "metadata": {},
   "source": [
    "# Experiments with models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb54628",
   "metadata": {},
   "source": [
    "## TfidfVectorizer + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef0f0296",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 37s, sys: 1min 10s, total: 5min 47s\n",
      "Wall time: 7min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model1 = NGramsClassifier()\n",
    "model1.train(list(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce94815c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted f1-score: 0.9876\n"
     ]
    }
   ],
   "source": [
    "score = model1.test(list(test_set))\n",
    "print(f\"Predicted {model1.metric_score_name}-score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accdb6a9",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca170e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new1 = NGramsClassifier(load_checkpoint_path='../results/n_grams_2022_04_05-04_14_30_PM.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19cacef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rus': 0.9336136862895978},\n",
       " {'hye': 0.9912336212229991},\n",
       " {'eng': 0.8872930009525644},\n",
       " {'aze': 0.8798388492971667},\n",
       " {'heb': 0.9880881315853616},\n",
       " {'bel': 0.8825106750133072},\n",
       " {'kat': 0.9921209009826181},\n",
       " {'heb': 0.9901148774378457},\n",
       " {'rus': 0.9799147537609325},\n",
       " {'rus': 0.944499004393118}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new1.predict_proba([i['sentence'] for i in list(test_set)[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bacb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_example = ['Привет дорогой друг, how is the weather in Georgia?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a488ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new1.predict_proba(text_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16532f89",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dad03ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model2 = TransformerLanguageDetection(device = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "433bd327",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training...:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "Train loss 1.800182580947876\n",
      "Val loss 1.273140788078308 f1-score 0.759765625\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 1/1 [00:50<00:00, 50.83s/it]\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss, val_score = model2.train(train_set, epochs=1, learning_rate=8e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a90b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing...: 100%|██████████| 40/40 [00:46<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1-score 0.7876953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model2.test(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88125a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Testing...: 100%|████████████████████████████| 40/40 [3:10:34<00:00, 285.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1-score 0.981640625\n"
     ]
    }
   ],
   "source": [
    "model_new2 = TransformerLanguageDetection(device = \"cpu\", load_checkpoint_path=\"../results/transformer_classifier_2022_04_05-04_19_12_PM.pt\")\n",
    "\n",
    "model_new2.test(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10512a3",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2b6971",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new2 = TransformerLanguageDetection(device = \"cpu\", load_checkpoint_path=\"../results/transformer_classifier_2022_04_05-04_19_12_PM.pt\")\n",
    "model_new2.predict([i['sentence'] for i in list(test_set)[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44bdc8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
